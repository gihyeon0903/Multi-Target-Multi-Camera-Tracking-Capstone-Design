{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\yolov5\\lib\\site-packages\\torchreid\\reid\\metrics\\rank.py:11: UserWarning: Cython evaluation (very fast so highly recommended) is unavailable, now use python evaluation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\user\\anaconda3\\envs\\yolov5\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2, time\n",
    "import torch\n",
    "\n",
    "from sort import *\n",
    "from custom_utils import filter_human, draw_rectangle, draw_matching_line, extract_obj_image, calculate_cosine_similarity_matrix, calculate_hungarian_algorithm, calculate_non_assignments, draw_id, Extract_bbox_info, calculate_weighted_similarity_matrix\n",
    "\n",
    "from re_identification import Global_Id_Identificator\n",
    "from osnet.feature_extraction import FeatureExtraction\n",
    "from feature_extractor_torchreid import Feature_Extractor_Torchreid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\user/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "WARNING  'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
      "WARNING  'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
      "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
      "    import torch\n",
      "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
      "    torch.save(ckpt, \"updated-model.pt\")\n",
      "\n",
      "YOLOv5  2023-5-24 Python-3.9.18 torch-2.0.0 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True);\n",
    "model.conf = 0.3\n",
    "model.float()\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: osnet_ain_x1_0\n",
      "- params: 2,193,616\n",
      "- flops: 978,878,352\n",
      "Successfully loaded pretrained weights from \"feature_extractor_weights/osnet_ain_ms_m_c.pth.tar\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n"
     ]
    }
   ],
   "source": [
    "# feature_extractor = FeatureExtraction(device='cuda')\n",
    "feature_extractor = Feature_Extractor_Torchreid()\n",
    "\n",
    "mot_tracker1 = Sort(max_age=500, iou_threshold=0.1, min_hits=1)\n",
    "mot_tracker2 = Sort(max_age=500, iou_threshold=0.1, min_hits=1)\n",
    "\n",
    "GII = Global_Id_Identificator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_path_list = ['./test_video/cam1_6.mp4', './test_video/cam2_6.mp4']\n",
    "\n",
    "vid = [cv2.VideoCapture(i) for i in cam_path_list]\n",
    "\n",
    "while(True):\n",
    "    # 이미지 read\n",
    "    ret1, image_cam1 = vid[0].read() # (h, w, 3)\n",
    "    ret2, image_cam2 = vid[1].read() \n",
    "    \n",
    "    image_cam1 = cv2.resize(image_cam1, (640, 360)) # (w, h)\n",
    "    image_cam2 = cv2.resize(image_cam2, (640, 360))\n",
    "    \n",
    "    if not ret1 or not ret2: \n",
    "        break\n",
    "    \n",
    "    # object detection\n",
    "    preds1 = model(image_cam1);\n",
    "    preds2 = model(image_cam2);\n",
    "    dets1 = preds1.pred[0].to('cpu').numpy()\n",
    "    dets2 = preds2.pred[0].to('cpu').numpy()\n",
    "\n",
    "    dets1 = filter_human(dets1)\n",
    "    dets2 = filter_human(dets2)\n",
    "\n",
    "    draw_image_cam1 = image_cam1.copy()\n",
    "    draw_image_cam2 = image_cam2.copy()\n",
    "    \n",
    "    ## SORT\n",
    "    trks1 = mot_tracker1.update(dets1)\n",
    "    trks2 = mot_tracker2.update(dets2)\n",
    "    \n",
    "    ## feature extraction\n",
    "    obj_image_cam1 = extract_obj_image(image_cam1, trks1)\n",
    "    obj_image_cam2 = extract_obj_image(image_cam2, trks2)\n",
    "    \n",
    "    features1, id1 = feature_extractor.prdict_multi_input(obj_image_cam1, trks1[:,-1])\n",
    "    features2, id2 = feature_extractor.prdict_multi_input(obj_image_cam2, trks2[:,-1])    \n",
    "    \n",
    "    ## compare feature using various methods\n",
    "        ## 1. cosin similarity\n",
    "    similarity_matrix = calculate_cosine_similarity_matrix(features1, features2)\n",
    "    weighted_similarity_matrix = calculate_weighted_similarity_matrix(similarity_matrix, trks1, trks2, GII)\n",
    "    \n",
    "    assignments, cos_similarities = calculate_hungarian_algorithm(weighted_similarity_matrix)\n",
    "    matched   = assignments[cos_similarities > 0.55]\n",
    "    unmatched = calculate_non_assignments(len(features1), len(features2), matched)\n",
    "    \n",
    "    ## extract matched/unmatched bbox info\n",
    "    matched_bbox, unmatched_bbox = Extract_bbox_info(matched, unmatched, trks1, trks2)\n",
    "    \n",
    "    ## re-identificationunmatched_bbox_cam2    \n",
    "    GII.update(matched, unmatched, matched_bbox, unmatched_bbox, (id1, id2))\n",
    "    GII.prev_id_tables_update()\n",
    "\n",
    "    \n",
    "    full_cam = np.concatenate([draw_image_cam1, draw_image_cam2], axis=0)\n",
    "        \n",
    "    ## draw rectangle\n",
    "    draw_rectangle(full_cam, trks1, cam_type=1)\n",
    "    draw_rectangle(full_cam, trks2, cam_type=2) \n",
    "    \n",
    "    ## draw matching line\n",
    "    draw_matching_line(full_cam, matched, (trks1, trks2), (id1, id2))\n",
    "    \n",
    "    ## draw ID \n",
    "    draw_id(full_cam, trks1, trks2, GII)\n",
    "    \n",
    "    cv2.imshow('full_cam', full_cam)\n",
    "    \n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "vid[0].release()\n",
    "vid[1].release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid[0].release()\n",
    "vid[1].release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
