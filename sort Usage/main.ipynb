{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import torch\n",
    "\n",
    "from sort import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\user/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "WARNING  'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
      "WARNING  'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
      "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
      "    import torch\n",
      "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
      "    torch.save(ckpt, \"updated-model.pt\")\n",
      "\n",
      "YOLOv5  2023-5-24 Python-3.9.18 torch-2.0.0 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "mot_tracker = Sort(max_age=10)\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True);\n",
    "model.float()\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_video_path = './test_video/test5.mp4'\n",
    "\n",
    "if os.path.isfile(test_video_path):\t# 해당 파일이 있는지 확인\n",
    "    vid = cv2.VideoCapture(test_video_path)\n",
    "\n",
    "i = 0\n",
    "while(True):\n",
    "    ret, image_show = vid.read()\n",
    "    image_show = cv2.resize(image_show, (500, 300))\n",
    "    \n",
    "    preds = model(image_show)\n",
    "    detections = preds.pred[0].to('cpu').numpy()\n",
    "    \n",
    "    # Filtering for human \n",
    "    person_class = (detections[:, -1] == 0)\n",
    "    detections = detections[person_class, :]\n",
    "    track_bbs_ids = mot_tracker.update(detections)\n",
    "    \n",
    "    for j in range(len(track_bbs_ids.tolist())):\n",
    "        \n",
    "        coords = track_bbs_ids.tolist()[j]\n",
    "        x1, y1, x2, y2 = int(coords[0]), int(coords[1]), int(coords[2]), int(coords[3])\n",
    "        name_idx = int(coords[4])\n",
    "        name = \"ID : {}\".format(str(name_idx))\n",
    "        color = (255, 255, 0)\n",
    "        \n",
    "        cv2.rectangle(image_show, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.putText(image_show, name, (x2, y2+10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "        cv2.imshow('image', image_show)\n",
    "        \n",
    "    cv2.imshow('image', image_show)\n",
    "    \n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
